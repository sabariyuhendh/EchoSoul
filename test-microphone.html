<!DOCTYPE html>
<html>
<head>
    <title>Microphone Test</title>
    <style>
        body { font-family: Arial, sans-serif; padding: 20px; background: #000; color: #fff; }
        button { padding: 10px 20px; margin: 10px; background: #007bff; color: white; border: none; border-radius: 5px; cursor: pointer; }
        #status { margin: 20px 0; padding: 10px; background: #333; border-radius: 5px; }
        #volume { width: 300px; height: 20px; background: #333; border-radius: 10px; margin: 10px 0; }
        #volumeBar { height: 100%; background: linear-gradient(90deg, #4CAF50, #FFC107, #FF5722); border-radius: 10px; width: 0%; transition: width 0.1s; }
    </style>
</head>
<body>
    <h1>Microphone Test for EchoSoul</h1>
    <button onclick="startTest()">Start Microphone Test</button>
    <button onclick="stopTest()">Stop Test</button>
    <div id="status">Click "Start Microphone Test" to begin</div>
    <div id="volume">
        <div id="volumeBar"></div>
    </div>
    <p>Volume: <span id="volumeText">0%</span></p>

    <script>
        let audioContext;
        let analyser;
        let microphone;
        let animationId;

        async function startTest() {
            try {
                document.getElementById('status').innerHTML = 'Requesting microphone access...';
                
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    } 
                });
                
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                microphone = audioContext.createMediaStreamSource(stream);
                
                analyser.fftSize = 512;
                analyser.smoothingTimeConstant = 0.3;
                microphone.connect(analyser);
                
                document.getElementById('status').innerHTML = '✅ Microphone connected! Try speaking or making noise.';
                monitorAudio();
                
            } catch (error) {
                let errorMessage = 'Error: ';
                if (error.name === 'NotAllowedError') {
                    errorMessage += 'Microphone access denied. Please allow microphone permissions.';
                } else if (error.name === 'NotFoundError') {
                    errorMessage += 'No microphone found. Please connect a microphone.';
                } else {
                    errorMessage += error.message;
                }
                document.getElementById('status').innerHTML = '❌ ' + errorMessage;
            }
        }

        function monitorAudio() {
            if (!analyser) return;
            
            const dataArray = new Uint8Array(analyser.frequencyBinCount);
            analyser.getByteFrequencyData(dataArray);
            
            const average = dataArray.reduce((a, b) => a + b) / dataArray.length;
            const volumePercent = Math.min((average / 128) * 100, 100);
            
            document.getElementById('volumeBar').style.width = volumePercent + '%';
            document.getElementById('volumeText').innerHTML = Math.round(volumePercent) + '%';
            
            animationId = requestAnimationFrame(monitorAudio);
        }

        function stopTest() {
            if (animationId) {
                cancelAnimationFrame(animationId);
            }
            if (audioContext) {
                audioContext.close();
            }
            document.getElementById('status').innerHTML = 'Test stopped.';
            document.getElementById('volumeBar').style.width = '0%';
            document.getElementById('volumeText').innerHTML = '0%';
        }
    </script>
</body>
</html>